/**
 * OpenAI Service - OpenAI API å®˜æ–¹ SDK åŒ…è£
 * è·è²¬ï¼šè™•ç† OpenAI API èª¿ç”¨ï¼Œtoken è¨ˆç®—ï¼ŒéŒ¯èª¤è™•ç†
 * é™åˆ¶ï¼šåƒ…ä¾›å…§éƒ¨æœå‹™èª¿ç”¨ï¼Œå¤–éƒ¨æ‡‰é€šé SemanticService
 */

class OpenAIService {
  /**
   * èª¿ç”¨ OpenAI Chat Completion API
   * @param {Object} options - API èª¿ç”¨åƒæ•¸
   * @param {string} options.prompt - ç”¨æˆ¶æç¤º
   * @param {string} options.model - æ¨¡å‹åç¨±ï¼ˆé»˜èªå¾ç’°å¢ƒè®Šæ•¸ï¼‰
   * @param {number} options.max_tokens - æœ€å¤§ token æ•¸é‡
   * @param {number} options.temperature - å‰µé€ æ€§åƒæ•¸
   * @returns {Promise<Object>} API éŸ¿æ‡‰çµæœ
   */
  static async complete(options = {}) {
    const {
      prompt,
      model = process.env.OPENAI_MODEL || 'gpt-3.5-turbo',
      maxTokens = 150,
      temperature = 0.7,
    } = options;

    if (!prompt) {
      throw new Error('OpenAIService: prompt is required');
    }

    if (!process.env.OPENAI_API_KEY) {
      throw new Error('OpenAIService: OPENAI_API_KEY environment variable is required');
    }

    try {
      // ğŸ§  ä½¿ç”¨çœŸæ­£çš„ OpenAI API é€²è¡Œèªç¾©ç†è§£
      const { OpenAI } = require('openai');
      
      const openai = new OpenAI({
        apiKey: process.env.OPENAI_API_KEY,
      });

      const response = await openai.chat.completions.create({
        model,
        messages: [
          {
            role: 'system',
            content: 'ä½ æ˜¯ä¸€å€‹èª²ç¨‹ç®¡ç†åŠ©æ‰‹ï¼Œå°ˆé–€å¹«åŠ©ç”¨æˆ¶åˆ†æèª²ç¨‹ç›¸é—œçš„è‡ªç„¶èªè¨€è¼¸å…¥ã€‚',
          },
          {
            role: 'user',
            content: prompt,
          },
        ],
        max_tokens: maxTokens,
        temperature,
      });

      return {
        success: true,
        content: response.choices[0].message.content,
        usage: response.usage,
        model: response.model,
        response_time: Date.now(),
      };
    } catch (error) {
      // ğŸ›¡ï¸ OpenAI API å¤±æ•—æ™‚ï¼Œå›é€€åˆ° mock æœå‹™ç¢ºä¿ç³»çµ±ç©©å®šæ€§
      console.warn('OpenAI API failed, falling back to mock service:', error.message);
      
      try {
        const mockResponse = await this.mockOpenAICall({
          model,
          messages: [
            {
              role: 'system',
              content: 'ä½ æ˜¯ä¸€å€‹èª²ç¨‹ç®¡ç†åŠ©æ‰‹ï¼Œå°ˆé–€å¹«åŠ©ç”¨æˆ¶åˆ†æèª²ç¨‹ç›¸é—œçš„è‡ªç„¶èªè¨€è¼¸å…¥ã€‚',
            },
            {
              role: 'user',
              content: prompt,
            },
          ],
          max_tokens: maxTokens,
          temperature,
        });

        return {
          success: true,
          content: mockResponse.choices[0].message.content,
          usage: mockResponse.usage,
          model: `${mockResponse.model}-mock-fallback`,
          response_time: mockResponse.response_time || Date.now(),
        };
      } catch (mockError) {
        throw new Error(`OpenAI Service Error: ${error.message}, Mock fallback also failed: ${mockError.message}`);
      }
    }
  }

  /**
   * åˆ†æèªç¾©æ„åœ–ï¼ˆå°ˆé–€ç”¨æ–¼ SemanticServiceï¼‰
   * @param {string} text - ç”¨æˆ¶è¼¸å…¥æ–‡æœ¬
   * @param {string} userId - ç”¨æˆ¶IDï¼ˆç”¨æ–¼ä¸Šä¸‹æ–‡ï¼‰
   * @returns {Promise<Object>} èªç¾©åˆ†æçµæœ
   */
  static async analyzeIntent(text, userId) {
    if (!text) {
      throw new Error('OpenAIService: text is required for intent analysis');
    }

    const prompt = `
åˆ†æä»¥ä¸‹ç”¨æˆ¶è¼¸å…¥ï¼Œè­˜åˆ¥èª²ç¨‹ç®¡ç†ç›¸é—œçš„æ„åœ–å’Œå¯¦é«”ï¼š

ç”¨æˆ¶è¼¸å…¥: "${text}"
ç”¨æˆ¶ID: ${userId}

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼ŒåŒ…å«ï¼š
{
  "intent": "æ„åœ–é¡å‹ (record_course, cancel_course, query_schedule, modify_course, set_reminder)",
  "confidence": "ä¿¡å¿ƒåº¦ (0.0-1.0)",
  "entities": {
    "course_name": "èª²ç¨‹åç¨±",
    "time": "æ™‚é–“ä¿¡æ¯",
    "date": "æ—¥æœŸä¿¡æ¯",
    "location": "åœ°é»",
    "teacher": "è€å¸«"
  },
  "reasoning": "åˆ†æç†ç”±"
}

åªå›æ‡‰ JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
`;

    const result = await this.complete({
      prompt,
      model: process.env.OPENAI_MODEL || 'gpt-3.5-turbo',
      max_tokens: 200,
      temperature: 0.3, // è¼ƒä½æº«åº¦ç¢ºä¿ä¸€è‡´æ€§
    });

    try {
      // å˜—è©¦è§£æ JSON å›æ‡‰
      const analysis = JSON.parse(result.content);

      return {
        success: true,
        analysis,
        usage: result.usage,
        model: result.model,
      };
    } catch (parseError) {
      // JSON è§£æå¤±æ•—ï¼Œå›å‚³åŸå§‹æ–‡æœ¬
      return {
        success: false,
        error: 'Failed to parse JSON response',
        raw_content: result.content,
        usage: result.usage,
        model: result.model,
      };
    }
  }

  /**
   * æ¨¡æ“¬ OpenAI API èª¿ç”¨ï¼ˆé–‹ç™¼/æ¸¬è©¦ç”¨ï¼‰
   * ç”Ÿç”¢ç’°å¢ƒæ‡‰æ›¿æ›ç‚ºçœŸå¯¦çš„ OpenAI SDK èª¿ç”¨
   * @param {Object} requestBody - API è«‹æ±‚é«”
   * @returns {Promise<Object>} æ¨¡æ“¬çš„ API éŸ¿æ‡‰
   */
  static async mockOpenAICall(requestBody) {
    const { model, messages } = requestBody;
    const userMessage = messages.find((m) => m.role === 'user')?.content || '';

    // æ¨¡æ“¬è™•ç†å»¶é²
    await new Promise((resolve) => {
      setTimeout(resolve, 100);
    });

    // ç°¡åŒ–çš„æ„åœ–åˆ†æé‚è¼¯ï¼ˆå¯¦éš›æ‡‰ç”± OpenAI è™•ç†ï¼‰
    let mockResponse = '';
    const promptTokens = Math.floor(userMessage.length / 4); // ç²—ç•¥ä¼°ç®—
    let completionTokens = 0;

    if (userMessage.includes('åˆ†æä»¥ä¸‹ç”¨æˆ¶è¼¸å…¥')) {
      // æ„åœ–åˆ†æè«‹æ±‚
      const analysisText = userMessage.match(/ç”¨æˆ¶è¼¸å…¥: "(.+?)"/)?.[1] || '';

      let intent = 'unknown';
      let confidence = 0.6;
      if (analysisText.includes('å–æ¶ˆ') || analysisText.includes('åˆªé™¤')) {
        intent = 'cancel_course';
        confidence = 0.8;
      } else if (analysisText.includes('æ–°å¢') || analysisText.includes('å®‰æ’') || analysisText.includes('é ç´„')) {
        intent = 'record_course';
        confidence = 0.8;
      } else if (analysisText.includes('æŸ¥è©¢') || analysisText.includes('çœ‹çœ‹') || analysisText.includes('èª²è¡¨')) {
        intent = 'query_schedule';
        confidence = 0.9;
      } else if (analysisText.includes('ä¿®æ”¹') || analysisText.includes('æ”¹æ™‚é–“')) {
        intent = 'modify_course';
        confidence = 0.8;
      } else if (analysisText.includes('æé†’')) {
        intent = 'set_reminder';
        confidence = 0.8;
      }

      mockResponse = JSON.stringify({
        intent,
        confidence,
        entities: {
          course_name: this.extractCourseName(analysisText),
          time: this.extractTime(analysisText),
          date: this.extractDate(analysisText),
          location: null,
          teacher: null,
        },
        reasoning: `åŸºæ–¼é—œéµè©åˆ†æè­˜åˆ¥ç‚º ${intent}`,
      });
    } else {
      // ä¸€èˆ¬å°è©±è«‹æ±‚
      mockResponse = 'æˆ‘æ˜¯èª²ç¨‹ç®¡ç†åŠ©æ‰‹ï¼Œå¯ä»¥å¹«æ‚¨ç®¡ç†èª²ç¨‹å®‰æ’ã€‚';
    }

    completionTokens = Math.floor(mockResponse.length / 4);

    return {
      id: `chatcmpl-mock-${Date.now()}`,
      object: 'chat.completion',
      created: Math.floor(Date.now() / 1000),
      model: model || 'gpt-3.5-turbo',
      choices: [
        {
          index: 0,
          message: {
            role: 'assistant',
            content: mockResponse,
          },
          finish_reason: 'stop',
        },
      ],
      usage: {
        prompt_tokens: promptTokens,
        completion_tokens: completionTokens,
        total_tokens: promptTokens + completionTokens,
      },
      response_time: Date.now(),
    };
  }

  /**
   * ğŸ§  AI é©…å‹•çš„èª²ç¨‹åç¨±æå–
   * @param {string} text - è¼¸å…¥æ–‡æœ¬
   * @returns {Promise<string|null>} èª²ç¨‹åç¨±
   */
  static async extractCourseName(text) {
    try {
      const prompt = `
è«‹å¾ä»¥ä¸‹ç”¨æˆ¶è¼¸å…¥ä¸­æå–èª²ç¨‹åç¨±ã€‚å¦‚æœæ²’æœ‰æ˜ç¢ºçš„èª²ç¨‹åç¨±ï¼Œè«‹è¿”å› nullã€‚

ç”¨æˆ¶è¼¸å…¥: "${text}"

è¦å‰‡ï¼š
1. åªæå–èª²ç¨‹çš„ä¸»è¦åç¨±éƒ¨åˆ†ï¼Œå»æ‰"èª²"å­—å¾Œç¶´
2. å¦‚æœæ˜¯ä¿®æ”¹/å–æ¶ˆèªå¥ï¼Œæå–å‹•ä½œå‰çš„èª²ç¨‹åç¨±ï¼Œä¸è¦åŒ…å«å‹•ä½œè©
3. å¦‚æœæ²’æœ‰æ˜ç¢ºèª²ç¨‹åç¨±ï¼Œè¿”å› null
4. åªè¿”å›èª²ç¨‹åç¨±ï¼Œä¸è¦å…¶ä»–æ–‡å­—
5. ä¸è¦åŒ…å«"ä¿®æ”¹"ã€"å–æ¶ˆ"ã€"åˆªé™¤"ã€"èª¿æ•´"ç­‰å‹•ä½œè©

ç¯„ä¾‹ï¼š
- "æ•¸å­¸èª²" â†’ "æ•¸å­¸"
- "ç¶²çƒæ”¹æˆä¸‹åˆå››é»" â†’ "ç¶²çƒ"  
- "ç›´æ’è¼ªèª²æ”¹æ™‚é–“" â†’ "ç›´æ’è¼ª"
- "å–æ¶ˆè‹±æ–‡èª²" â†’ "è‹±æ–‡"
- "ä¿®æ”¹ç‰©ç†èª²æ™‚é–“" â†’ "ç‰©ç†"
- "æ˜å¤©ä¸‹åˆ2é»" â†’ null (æ²’æœ‰èª²ç¨‹åç¨±)

èª²ç¨‹åç¨±:`;

      const result = await this.complete({
        prompt,
        model: 'gpt-3.5-turbo',
        maxTokens: 50,
        temperature: 0.1, // ä½æº«åº¦ç¢ºä¿ä¸€è‡´æ€§
      });

      if (result.success) {
        const extracted = result.content.trim();
        // è™•ç† AI å›æ‡‰ï¼Œéæ¿¾ç„¡æ•ˆçµæœ
        if (extracted && 
            extracted !== 'null' && 
            extracted !== 'NULL' &&
            extracted !== 'ç„¡' &&
            extracted !== 'æ²’æœ‰' &&
            extracted.length <= 20 && 
            extracted.length >= 1) {
          return extracted;
        }
      }
      
      return null;
    } catch (error) {
      console.warn('AI course name extraction failed, using fallback:', error.message);
      // å›é€€åˆ°åŸæœ‰æ¨¡å¼åŒ¹é…
      return this.fallbackExtractCourseName(text);
    }
  }

  /**
   * å›é€€èª²ç¨‹åç¨±æå–ï¼ˆä¿æŒç³»çµ±ç©©å®šæ€§ï¼‰
   * @param {string} text - è¼¸å…¥æ–‡æœ¬  
   * @returns {string|null} èª²ç¨‹åç¨±
   */
  static fallbackExtractCourseName(text) {
    const coursePatterns = [
      /(æ•¸å­¸|è‹±æ–‡|ç‰©ç†|åŒ–å­¸|ç”Ÿç‰©|æ­·å²|åœ°ç†|åœ‹æ–‡|è‹±èª|ä¸­æ–‡|æ³•èª|å¾·èª|æ—¥èª|éŸ“èª|è¥¿ç­ç‰™èª|ç¾©å¤§åˆ©èª|ä¿„èª|é˜¿æ‹‰ä¼¯èª|ç±ƒçƒ|è¶³çƒ|æ’çƒ|ç¾½æ¯›çƒ|ä¹’ä¹“çƒ|ç¶²çƒ|æ¸¸æ³³|è·‘æ­¥|å¥èº«|ç‘œä¼½|èˆè¹ˆ|æ­¦è¡“|è·†æ‹³é“|ç©ºæ‰‹é“|æŸ”é“|åŠé“|ç›´æ’è¼ª|é‹¼ç´|å‰ä»–|å°æç´)èª²?/,
      /([ä¸€-é¾¯]+èª)èª²?/,
      /([ä¸€-é¾¯]+)èª²/,
      /([ä¸€-é¾¯]+)ç­/,
      // ğŸ’¡ æ–°å¢ï¼šæå–ä¿®æ”¹èªå¥ä¸­çš„èª²ç¨‹åç¨±
      /^([^ä¿®æ”¹å–æ¶ˆåˆªé™¤èª¿æ•´æ›´æ”¹è®Šæ›´æ”¹æˆæ”¹åˆ°æ›æˆæ›åˆ°]{1,10})(?=ä¿®æ”¹|å–æ¶ˆ|åˆªé™¤|èª¿æ•´|æ›´æ”¹|è®Šæ›´|æ”¹æˆ|æ”¹åˆ°|æ›æˆ|æ›åˆ°)/,
    ];

    for (const pattern of coursePatterns) {
      const match = text.match(pattern);
      if (match) {
        const courseName = match[1] || match[0];
        return courseName.replace(/èª²$/, '');
      }
    }

    return null;
  }

  /**
   * å¾æ–‡æœ¬ä¸­æå–æ™‚é–“ä¿¡æ¯
   * @param {string} text - è¼¸å…¥æ–‡æœ¬
   * @returns {string|null} æ™‚é–“ä¿¡æ¯
   */
  static extractTime(text) {
    const timePatterns = [
      // HH:MM æ ¼å¼
      /(\d{1,2}:\d{2})/,
      
      // ğŸ”§ ä¿®å¾©ï¼šä¸­æ–‡æ•¸å­—+åˆ†é˜æ•¸ (ä¸‹åˆå››é»20)
      /(ä¸Šåˆ|ä¸‹åˆ|æ—©ä¸Š|ä¸­åˆ|æ™šä¸Š)?\s*(åä¸€|åäºŒ|ä¸€|äºŒ|ä¸‰|å››|äº”|å…­|ä¸ƒ|å…«|ä¹|å)[é»ç‚¹](\d{1,2})/,
      
      // æ•¸å­—+åˆ†é˜æ•¸ (3é»45, 14é»30)
      /(\d{1,2})[é»ç‚¹](\d{1,2})/,
      
      // ä¸Šåˆä¸‹åˆ+æ•¸å­—æ™‚é–“+åˆ†é˜æ•¸ (ä¸Šåˆ9é»15)
      /(ä¸Šåˆ|ä¸‹åˆ|æ—©ä¸Š|ä¸­åˆ|æ™šä¸Š)\s*(\d{1,2})[é»ç‚¹](\d{1,2})?/,
      
      // ä¸­æ–‡æ•¸å­—æ™‚é–“ (å››é», åä¸€é»)
      /(ä¸Šåˆ|ä¸‹åˆ|æ—©ä¸Š|ä¸­åˆ|æ™šä¸Š)?\s*(åä¸€|åäºŒ|ä¸€|äºŒ|ä¸‰|å››|äº”|å…­|ä¸ƒ|å…«|ä¹|å)[é»ç‚¹]/,
      
      // æ•¸å­—æ™‚é–“ (3é», 14é») 
      /(\d{1,2})[é»ç‚¹]/,
      
      // ä¸Šåˆä¸‹åˆ+æ•¸å­—æ™‚é–“ (ä¸‹åˆ3é»)
      /(ä¸Šåˆ|ä¸‹åˆ|æ—©ä¸Š|ä¸­åˆ|æ™šä¸Š)\s*(\d{1,2})[é»ç‚¹]/,
      
      // æ™‚æ®µè©
      /(æ—©ä¸Š|ä¸­åˆ|æ™šä¸Š)/,
    ];

    for (const pattern of timePatterns) {
      const match = text.match(pattern);
      if (match) {
        return match[0];
      }
    }

    return null;
  }

  /**
   * å¾æ–‡æœ¬ä¸­æå–æ—¥æœŸä¿¡æ¯
   * @param {string} text - è¼¸å…¥æ–‡æœ¬
   * @returns {string|null} æ—¥æœŸä¿¡æ¯
   */
  static extractDate(text) {
    const datePatterns = [
      /(ä»Šå¤©|æ˜å¤©|å¾Œå¤©|æ˜¨å¤©|å‰å¤©)/,
      /(\d{4}-\d{2}-\d{2})/,
      /(\d{1,2})æœˆ(\d{1,2})æ—¥/,
      /(é€±ä¸€|é€±äºŒ|é€±ä¸‰|é€±å››|é€±äº”|é€±å…­|é€±æ—¥)/,
      /(æ˜ŸæœŸä¸€|æ˜ŸæœŸäºŒ|æ˜ŸæœŸä¸‰|æ˜ŸæœŸå››|æ˜ŸæœŸäº”|æ˜ŸæœŸå…­|æ˜ŸæœŸæ—¥)/,
    ];

    for (const pattern of datePatterns) {
      const match = text.match(pattern);
      if (match) {
        return match[0];
      }
    }

    return null;
  }

  /**
   * è¨ˆç®— token æˆæœ¬ï¼ˆæ–°å°å¹£ï¼‰
   * @param {number} totalTokens - ç¸½ token æ•¸
   * @param {string} model - æ¨¡å‹åç¨±
   * @returns {number} æˆæœ¬ï¼ˆæ–°å°å¹£ï¼‰
   */
  static calculateCost(totalTokens, model = 'gpt-3.5-turbo') {
    // GPT-3.5-turbo å®šåƒ¹ï¼ˆåƒè€ƒå€¼ï¼Œå¯¦éš›ä»¥ OpenAI å®˜æ–¹ç‚ºæº–ï¼‰
    const pricing = {
      'gpt-3.5-turbo': 0.000002, // USD per token
      'gpt-4': 0.00003, // USD per token
    };

    const usdRate = 31.5; // USD to TWD åŒ¯ç‡ï¼ˆåƒè€ƒå€¼ï¼‰
    const pricePerToken = pricing[model] || pricing['gpt-3.5-turbo'];

    return totalTokens * pricePerToken * usdRate;
  }
}

module.exports = OpenAIService;
